base:
  N: 10  # 节点数
  T: 11000  # 总时间步数
  T_train_val: 10000  # 训练和验证的时间步数
  train_ratio: 0.8  # 训练集占比
  T_train: 8000 # 训练的时间步数
  T_val: 2000  # 验证的时间步数
  T_test: 1000  # 测试的时间步数
#  data_type: "ar1"  # 数据类型

data_generation:

  load_data:
    node_mean: 50.0  # 节点的load的初始值/均值的均值
    node_var: 10.0  # 节点的load的初始值/均值的方差
    node_iid_var: 5.0  # 节点的load值的iid方法的方差
    node_theta: 0.9  # 节点的load值的ar1方法的自相关系数

  latency:
    mean: 0.0  # 延迟的均值
    var: 0.0  # 延迟的方差
    iid_var: 0.0  # 延迟的iid方法的方差
    theta: 0.0  # 延迟的ar1方法的自相关系数

exp4:
  batch_size: 64  # Batch size
  seq_length: 20  # Sequence length
  input_size: 10  # Input size
  output_size: 10  # Output size
  learning_rate: 0.001  # Learning rate
  num_workers: 24  # Number of workers for DataLoader
  num_epochs: 100  # Number of epochs
  device: 'cuda'  # Device
  mix_precision: True  # Mixed precision training

  # 早停的参数
  patience_epochs: 6  # 'patience_epochs' 个 epoch 没有提升，就停止训练
  min_delta: 1e-3  # 当监控指标的变化小于 min_delta 时，就视为没有提升

  # 调度器的参数
  mode: 'min'  # 'min' 表示监控指标的值越小越好，'max' 表示监控指标的值越大越好
  factor: 0.1  # 学习率调度器的缩放因子
  patience_lr: 2  # 'patience_lr' 个 epoch 没有提升，就缩放学习率
  min_lr: 1e-6  # 学习率的下限
  threshold: 1e-2  # 监控指标的变化小于 threshold 时，就视为没有提升

  ARconfig:
    order: 5  # AR 模型的阶数

  LSTMconfig:
    hidden_size: 128  # LSTM 模型的隐藏层大小
    num_layers: 4  # LSTM 模型的层数
    dropout_prob: 0.2  # LSTM 模型的 dropout 率
    weight_decay: 1e-4  # LSTM 模型的权重衰减
  #    batch_first: True  # LSTM 模型的输入是否 batch_first

  GNNconfig:
    hidden_size: 128  # GNN 模型的隐藏层大小
    num_layers: 4  # GNN 模型的层数
#    dropout: 0.2  # GNN 模型的 dropout 率
#    batch_first: True  # GNN 模型的输入是否 batch_first
#    num_heads: 8  # GNN 模型的头数
#    concat: True  # GNN 模型的是否拼接多头的输出