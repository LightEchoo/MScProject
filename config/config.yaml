path:
  global_path: "E:/Study in the UK/Project/MScProject"  # 项目的根目录

base:
  N: 10  # 节点数
  T: 11000  # 总时间步数
  T_train_val: 10000  # 训练和验证的时间步数
  train_ratio: 0.8  # 训练集占比
  T_train: 8000 # 训练的时间步数
  T_val: 2000  # 验证的时间步数
  T_test: 1000  # 测试的时间步数
  lambda_load: 0.5  # load和latency的权重, 0.5表示load的权重
  top_k: [1, 2, 3, 4, 5]  # top-k 的值

data_generation:
  load_data:
    node_load_mean_mean: 50.0  # 节点的load的初始值/均值的均值
    node_load_mean_std: 10.0  # 节点的load的初始值/均值的方差
    node_load_iid_std: 5.0  # 节点的load值的iid方法的方差
    node_load_ar1_theta: 0.9  # 节点的load值的ar1方法的自相关系数

  latency_data:
    node_latency_mean_mean: 30.0  # 节点的latency的初始值/均值的均值
    node_latency_mean_std: 10.0  # 节点的latency的初始值/均值的方差
    node_latency_ar1_theta: 0.9  # 节点的latency值的ar1方法的自相关系数

  reward_parameters:
    iid:
      alpha_load_0: 36.0
      alpha_latency_1: 0.031

    ar1:
      alpha_load_0: 36.0
      alpha_latency_1: 0.020

  reward_parameters_slider:
    alpha_load_0:
      value: 1.0
      min: 0.001
      max: 40.0
      step: 0.01
      description: 'alpha_load_0'
    alpha_latency_0:
      value: 1.0
      min: 0.001
      max: 6.0
      step: 0.01
      description: 'alpha_latency_0'
    alpha_latency_1:
      value: 0.5
      min: 0.0001
      max: 0.5
      step: 0.001
      description: 'alpha_latency_1'

epsilon_greedy:
  #  epsilons : [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 0.8, 0.9]  # epsilon 的值，在动态调整图中不起作用
  dynamic_plot:
    epsilon_min: 0.001 # epsilon 的最小值
    epsilon_max: 0.5 # epsilon 的最大值
    epsilon_step: 0.01 # epsilon 的步长
    epsilon_default_value: 0.1 # epsilon 的默认值

  evaluation:
    epsilon_min: 0.0001 # epsilon 的最小值
    epsilon_max: 0.2001 # epsilon 的最大值
    epsilon_step: 0.0005 # epsilon 的步长

adaptive_epsilon_greedy:
  #  init_epsilons : [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 0.8, 0.9]  # epsilon 的值，在动态调整图中不起作用
  #  min_epsilon: 0.05 # epsilon 的最小值，在动态调整图中不起作用
  dynamic_plot:
    init_epsilon_min: 0.001 # epsilon 的最小值
    init_epsilon_max: 0.5 # epsilon 的最大值
    init_epsilon_step: 0.01 # epsilon 的步长
    init_epsilon_default_value: 0.1 # epsilon 的默认值

    min_epsilon_min: 0.001 # 算法可以取到的 epsilon 的最小值的范围的最小值
    min_epsilon_max: 0.1 # 算法可以取到的 epsilon 的最小值的范围的最大值
    min_epsilon_step: 0.001 # 算法可以取到的 epsilon 的最小值的范围的步长
    min_epsilon_default_value: 0.05 # 算法可以取到的 epsilon 的最小值的默认值

  evaluation:
    init_epsilon_min: 0.0001 # epsilon 的最小值
    init_epsilon_max: 0.1001 # epsilon 的最大值
    init_epsilon_step: 0.0005 # epsilon 的步长
    min_epsilon: 0.05 # 算法可以取到的 epsilon 的最小值

dynamic_adaptive_epsilon_greedy:
  #  init_epsilons : [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 0.8, 0.9]  # epsilon 的值
  min_epsilon: 0.05 # epsilon 的最小值
  max_epsilon: 0.8 # epsilon 的最大值
  #  threshold: 0.25 # epsilon的变化阈值
  #  percentiles: 80 # 阈值选取的之前的单步遗憾的百分位数，表示有百分之多少的遗憾小于阈值，动态绘制时不起作用
  dynamic_plot:
    init_epsilon_min: 0.001 # epsilon 的最小值
    init_epsilon_max: 0.5 # epsilon 的最大值
    init_epsilon_step: 0.01 # epsilon 的步长
    init_epsilon_default_value: 0.1 # epsilon 的默认值

    percentiles_min: 50 # 阈值选取的之前的单步遗憾的百分位数的最小值
    percentiles_max: 100 # 阈值选取的之前的单步遗憾的百分位数的最大值
    percentiles_step: 1 # 阈值选取的之前的单步遗憾的百分位数的步长
    percentiles_default_value: 80 # 阈值选取的之前的单步遗憾的百分位数的默认值

  evaluation:
    init_epsilon_min: 0.0001 # epsilon 的最小值
    init_epsilon_max: 0.1001 # epsilon 的最大值
    init_epsilon_step: 0.0005 # epsilon 的步长
    default_percentiles: 80 # 阈值选取的之前的单步遗憾的百分位数

    percentiles_min: 50 # 阈值选取的之前的单步遗憾的百分位数的最小值
    percentiles_max: 100 # 阈值选取的之前的单步遗憾的百分位数的最大值
    percentiles_step: 1 # 阈值选取的之前的单步遗憾的百分位数的步长
    default_init_epsilon: 0.04 # epsilon 的默认值

boltzmann:
  dynamic_plot:
    temperature_min: 0.01 # temperature 的最小值
    temperature_max: 1.01 # temperature 的最大值
    temperature_step: 0.001 # temperature 的步长
    temperature_default_value: 0.5 # temperature 的默认值

  evaluation:
    temperature_min: 0.01 # temperature 的最小值
    temperature_max: 0.25 # temperature 的最大值
    temperature_step: 0.001 # temperature 的步长

thompson_sampling: None # 无参数

ucb:
  #  c: 1.5  # ucb 的参数
  dynamic_plot:
    c_min: 0.001 # ucb 的参数的最小值
    c_max: 1 # ucb 的参数的最大值
    c_step: 0.001 # ucb 的参数的步长
    c_default_value: 0.5 # ucb 的参数的默认值

  evaluation:
    c_min: 0.001 # ucb 的参数的最小值
    c_max: 1.0   # ucb 的参数的最大值
    c_step: 0.001 # ucb 的参数的步长

exp3:
  dynamic_plot:
    gamma_min: 0.001 # eta 的最小值
    gamma_max: 1.0 # eta 的最大值
    gamma_step: 0.001 # eta 的步长
    gamma_default_value: 0.01 # eta 的默认值

  evaluation:
    gamma_min: 0.001 # eta 的最小值
    gamma_max: 1.0 # eta 的最大值
    gamma_step: 0.001 # eta 的步长

exp_ix:
  dynamic_plot:
    eta_min: 0.01 # eta 的最小值
    eta_max: 1.01 # eta 的最大值
    eta_step: 0.01 # eta 的步长
    eta_default_value: 0.5 # eta 的默认值

  evaluation:
    eta_min: 0.01 # eta 的最小值
    eta_max: 1.01 # eta 的最大值
    eta_step: 0.01 # eta 的步长

exp4:
  batch_size: 64  # Batch size
  seq_length: 20  # Sequence length
  input_size: 10  # Input size
  output_size: 10  # Output size
  learning_rate: 0.001  # Learning rate
  num_workers: 16  # Number of workers for DataLoader
  num_epochs: 100  # Number of epochs
  device: 'cuda'  # Device
  mix_precision: True  # Mixed precision training

  # 早停的参数
  patience_epochs: 6  # 'patience_epochs' 个 epoch 没有提升，就停止训练
  min_delta: 1e-3  # 当监控指标的变化小于 min_delta 时，就视为没有提升

  # 调度器的参数
  mode: 'min'  # 'min' 表示监控指标的值越小越好，'max' 表示监控指标的值越大越好
  factor: 0.1  # 学习率调度器的缩放因子
  patience_lr: 2  # 'patience_lr' 个 epoch 没有提升，就缩放学习率
  min_lr: 1e-6  # 学习率的下限
  threshold: 1e-2  # 监控指标的变化小于 threshold 时，就视为没有提升

  ARconfig:
    order: 5  # AR 模型的阶数

  LSTMconfig:
    hidden_size: 128  # LSTM 模型的隐藏层大小
    num_layers: 4  # LSTM 模型的层数
    dropout_prob: 0.2  # LSTM 模型的 dropout 率
    weight_decay: 1e-4  # LSTM 模型的权重衰减
  #    batch_first: True  # LSTM 模型的输入是否 batch_first

  GNNconfig:
    hidden_size: 128  # GNN 模型的隐藏层大小
    num_layers: 4  # GNN 模型的层数
#    dropout: 0.2  # GNN 模型的 dropout 率
#    batch_first: True  # GNN 模型的输入是否 batch_first
#    num_heads: 8  # GNN 模型的头数
#    concat: True  # GNN 模型的是否拼接多头的输出