{
 "cells": [
  {
   "cell_type": "code",
   "id": "95e520b517cf6f5c",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import scipy.stats as stats\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, config: DictConfig, if_save: bool) -> None:\n",
    "        \"\"\"\n",
    "        初始化 DataGenerate 类，接受一个 omegaconf 的 DictConfig 对象作为配置，并将\n",
    "        所需的配置项提取为类属性。\n",
    "\n",
    "        :param config: 配置文件，使用 omegaconf 加载的 DictConfig 对象\n",
    "        \"\"\"\n",
    "        # 提取并保存配置项\n",
    "        self.config = config\n",
    "        base_config = config.base\n",
    "        data_gen_config = config.data_generation.load_data\n",
    "        latency_gen_config = config.data_generation.latency_data\n",
    "\n",
    "        self.N = base_config.N\n",
    "        self.T = base_config.T\n",
    "        self.T_train_val = base_config.T_train_val\n",
    "        self.T_test = base_config.T_test\n",
    "\n",
    "        self.node_load_mean_mean = data_gen_config.node_load_mean_mean\n",
    "        self.node_load_mean_std = data_gen_config.node_load_mean_std\n",
    "        self.node_load_iid_std = data_gen_config.node_load_iid_std\n",
    "        self.node_load_ar1_theta = data_gen_config.node_load_ar1_theta\n",
    "\n",
    "        self.node_latency_mean_mean = latency_gen_config.node_latency_mean_mean\n",
    "        self.node_latency_mean_std = latency_gen_config.node_latency_mean_std\n",
    "        self.node_latency_ar1_theta = latency_gen_config.node_latency_ar1_theta\n",
    "\n",
    "        # 初始化其他属性\n",
    "        self.means_loads = self._generate_means(self.node_load_mean_mean, self.node_load_mean_std)  # 生成节点的平均负载\n",
    "        self.load_iid, self.load_mean_iid = self._generate_iid_data(self.node_load_iid_std, self.means_loads)  # 生成iid数据\n",
    "        self.load_ar1, self.load_mean_ar1 = self._generate_ar1_data(self.node_load_ar1_theta, self.means_loads)  # 生成ar1数据\n",
    "\n",
    "        self.means_latencies = self._generate_means(self.node_latency_mean_mean, self.node_latency_mean_std)  # 生成节点的平均延迟\n",
    "        self.latency_iid, self.latency_mean_iid = self._generate_iid_data(self.node_latency_mean_mean, self.means_latencies, data_type='latency')  # 生成iid延迟数据\n",
    "        self.latency_ar1, self.latency_mean_ar1 = self._generate_ar1_data(self.node_latency_ar1_theta, self.means_latencies, data_type='latency')  # 生成ar1延迟数据\n",
    "        \n",
    "        # 保存数据并打印信息\n",
    "        self._save_data() if if_save else None\n",
    "        self.print_data_generate_info()\n",
    "        self.plot_original_means()\n",
    "        self.plot_combined_data(0)\n",
    "        self.plot_comparison()\n",
    "\n",
    "        # 初始化最佳alpha值\n",
    "        self.best_iid_alpha_load_0 = None\n",
    "        self.best_iid_alpha_latency_1 = None\n",
    "        self.best_ar1_alpha_load_0 = None\n",
    "        self.best_ar1_alpha_latency_1 = None\n",
    "        \n",
    "        # 初始化要放到配置文件中的最佳alpha值\n",
    "        self.config_best_iid_alpha_load_0 = None\n",
    "        self.config_best_iid_alpha_latency_1 = None\n",
    "        self.config_best_ar1_alpha_load_0 = None\n",
    "        self.config_best_ar1_alpha_latency_1 = None\n",
    "        \n",
    "        # 计算最佳alpha值\n",
    "        self.calculate_best_alpha()\n",
    "        # 更新配置文件\n",
    "        # self.update_config_with_best_alphas()\n",
    "        \n",
    "    def calculate_best_alpha(self) -> None:\n",
    "        # 计算最佳的alpha值\n",
    "        max_iid_load = np.max(self.load_iid)\n",
    "        self.best_iid_alpha_load_0 = 1 + max_iid_load - 1e-3  # 动态计算load_reward_0的最佳alpha值，减去一个小值以增强稳定性\n",
    "        # iid_aloha_load_1 没有alpha值，因为它是归一化的\n",
    "        # iid_alpha_latency_0 也没有实际使用，因此不需要计算\n",
    "        # iid_alpha_latency_1 在函数search_and_plot_best_latency_reward_1_alpha中计算\n",
    "\n",
    "        max_ar1_load = np.max(self.load_ar1)\n",
    "        self.best_ar1_alpha_load_0 = 1 + max_ar1_load - 1e-3  # 动态计算load_reward_0的最佳alpha值，减去一个小值以增强稳定性\n",
    "        # ar1_aloha_load_1 没有alpha值，因为它是归一化的\n",
    "        # ar1_alpha_latency_0 也没有实际使用，因此不需要计算\n",
    "        # ar1_alpha_latency_1 在函数search_and_plot_best_latency_reward_1_alpha中计算\n",
    "\n",
    "        self.best_iid_alpha_latency_1, self.best_ar1_alpha_latency_1 =self.search_and_plot_best_latency_reward_1_alpha(self.latency_iid, self.latency_ar1)\n",
    "        # self.search_and_plot_best_latency_reward_1_alpha(self.latency_iid, self.latency_ar1)\n",
    "\n",
    "        self.config_best_iid_alpha_load_0 = float(round(self.best_iid_alpha_load_0, 3))\n",
    "        self.config_best_iid_alpha_latency_1 = float(round(self.best_iid_alpha_latency_1, 3))\n",
    "        self.config_best_ar1_alpha_load_0 = float(round(self.best_ar1_alpha_load_0, 3))\n",
    "        self.config_best_ar1_alpha_latency_1 = float(round(self.best_ar1_alpha_latency_1, 3))\n",
    "        # print(f\"最佳的 iid_alpha_load_0: {self.config_best_iid_alpha_load_0}\")\n",
    "        print(f\"最佳的 iid_alpha_latency_1: {self.config_best_iid_alpha_latency_1}\")\n",
    "        # print(f\"最佳的 ar1_alpha_load_0: {self.config_best_ar1_alpha_load_0}\")\n",
    "        print(f\"最佳的 ar1_alpha_latency_1: {self.config_best_ar1_alpha_latency_1}\")\n",
    "\n",
    "    def update_config_with_best_alphas(self):\n",
    "        # 将 alpha 值限制在小数点后三位并更新配置中的值\n",
    "        # 创建一个新的字典，只包含更新的值\n",
    "        updated_values = DictConfig({\n",
    "            \"reward_parameters\": {\n",
    "                \"iid\": {\n",
    "                    \"alpha_load_0\": self.config_best_iid_alpha_load_0,\n",
    "                    \"alpha_latency_1\": self.config_best_iid_alpha_latency_1,\n",
    "                },\n",
    "                \"ar1\": {\n",
    "                    \"alpha_load_0\": self.config_best_ar1_alpha_load_0,\n",
    "                    \"alpha_latency_1\": self.config_best_ar1_alpha_latency_1,\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "\n",
    "        # 加载原始配置文件\n",
    "        original_config = OmegaConf.load(\"config/config.yaml\")\n",
    "\n",
    "        # 只更新特定值\n",
    "        OmegaConf.merge(original_config, updated_values)\n",
    "\n",
    "        # 保存配置回文件\n",
    "        OmegaConf.save(config=original_config, f=\"config/config.yaml\")\n",
    "        \n",
    "\n",
    "    def calculate_kl_divergence(self, y, x):\n",
    "        # 计算拟合的 lambda 值\n",
    "        fitted_lambda = 1 / np.mean(y)\n",
    "        \n",
    "        # 计算 PDF 并检查其有效性\n",
    "        pdf_values = stats.expon.pdf(x, scale=1/fitted_lambda)\n",
    "        if not np.all(np.isfinite(pdf_values)):\n",
    "            raise ValueError(\"The computed PDF contains invalid values (NaN or Inf).\")\n",
    "\n",
    "        # 如果 pdf_values 中有无效值，将其替换为一个小的正数，以避免后续计算中的问题\n",
    "        pdf_values = np.where(np.isfinite(pdf_values) & (pdf_values > 0), pdf_values, 1e-10)\n",
    "    \n",
    "        # 计算 KL 散度\n",
    "        kl_divergence = stats.entropy(y, pdf_values)\n",
    "        return kl_divergence\n",
    "    \n",
    "    def calculate_entropy(self, y):\n",
    "        probabilities = y / np.sum(y)\n",
    "        probabilities = probabilities[probabilities > 0]\n",
    "        entropy = -np.sum(probabilities * np.log(probabilities))\n",
    "        return entropy\n",
    "    \n",
    "    def calculate_std_dev(self, y):\n",
    "        return np.std(y)\n",
    "    \n",
    "    def search_and_plot_best_latency_reward_1_alpha(self, latency_data_iid: np.ndarray, latency_data_ar1: np.ndarray) -> tuple[float, float]:\n",
    "        \"\"\"\n",
    "        计算不同的度量方法（KL散度、信息熵、标准差）下的最佳alpha值，并绘制相关分布图。\n",
    "        \n",
    "        参数:\n",
    "        - latency_data_iid: iid延迟数据的二维数组\n",
    "        - latency_data_ar1: ar1延迟数据的二维数组\n",
    "        \n",
    "        返回:\n",
    "        - iid_latency_alpha_kl: iid延迟数据的KL散度最佳alpha值, 可以认为是iid_reward_1的最佳alpha值\n",
    "        - ar1_latency_alpha_std: ar1延迟数据的标准差最佳alpha值，可以认为是ar1_reward_1的最佳alpha值\n",
    "        \"\"\"\n",
    "    \n",
    "        def find_best_alpha(latency_data: np.ndarray, metric: str):\n",
    "            max_node_index = np.argmax(np.max(latency_data, axis=1))\n",
    "            max_node_values = latency_data[max_node_index, :]\n",
    "    \n",
    "            x = max_node_values\n",
    "            alphas = np.around(np.arange(0.001, 1.001, step=0.0001), decimals=3)\n",
    "            best_alpha = None\n",
    "            best_metric_value = float('-inf') if metric != 'kl' else float('inf')\n",
    "    \n",
    "            for alpha in tqdm(alphas, desc=f\"Calculating best alpha for {metric}\", leave=False):\n",
    "                y = np.exp(-alpha * x)\n",
    "    \n",
    "                if metric == 'kl':\n",
    "                    metric_value = self.calculate_kl_divergence(y, x)\n",
    "                    if metric_value < best_metric_value:\n",
    "                        best_metric_value = metric_value\n",
    "                        best_alpha = alpha\n",
    "                elif metric == 'entropy':\n",
    "                    metric_value = self.calculate_entropy(y)\n",
    "                    if metric_value > best_metric_value:\n",
    "                        best_metric_value = metric_value\n",
    "                        best_alpha = alpha\n",
    "                elif metric == 'std':\n",
    "                    metric_value = self.calculate_std_dev(y)\n",
    "                    if metric_value > best_metric_value:\n",
    "                        best_metric_value = metric_value\n",
    "                        best_alpha = alpha\n",
    "    \n",
    "            return best_alpha, max_node_index\n",
    "    \n",
    "        # 计算不同的度量方法的最佳alpha\n",
    "        print(\"Calculating best alphas...\")\n",
    "        iid_latency_alpha_kl, iid_index_kl = find_best_alpha(latency_data_iid, 'kl')\n",
    "        ar1_latency_alpha_kl, ar1_index_kl = find_best_alpha(latency_data_ar1, 'kl')\n",
    "        iid_latency_alpha_entropy, iid_index_entropy = find_best_alpha(latency_data_iid, 'entropy')\n",
    "        ar1_latency_alpha_entropy, ar1_index_entropy = find_best_alpha(latency_data_ar1, 'entropy')\n",
    "        iid_latency_alpha_std, iid_index_std = find_best_alpha(latency_data_iid, 'std')\n",
    "        ar1_latency_alpha_std, ar1_index_std = find_best_alpha(latency_data_ar1, 'std')\n",
    "        # 绘制6张图并合并为一张大图\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        ax = axs.ravel()\n",
    "    \n",
    "        # KL散度\n",
    "        ax[0].hist(np.exp(-iid_latency_alpha_kl * latency_data_iid[iid_index_kl, :]), bins=30, density=True, alpha=0.6, color='g')\n",
    "        ax[0].set_title(f'Iid Latency KL - Best alpha = {iid_latency_alpha_kl:.3f}')\n",
    "        ax[1].hist(np.exp(-ar1_latency_alpha_kl * latency_data_ar1[ar1_index_kl, :]), bins=30, density=True, alpha=0.6, color='g')\n",
    "        ax[1].set_title(f'Ar1 Latency KL - Best alpha = {ar1_latency_alpha_kl:.3f}')\n",
    "    \n",
    "        # 信息熵\n",
    "        ax[2].hist(np.exp(-iid_latency_alpha_entropy * latency_data_iid[iid_index_entropy, :]), bins=30, density=True, alpha=0.6, color='g')\n",
    "        ax[2].set_title(f'Iid Latency Entropy - Best alpha = {iid_latency_alpha_entropy:.3f}')\n",
    "        ax[3].hist(np.exp(-ar1_latency_alpha_entropy * latency_data_ar1[ar1_index_entropy, :]), bins=30, density=True, alpha=0.6, color='g')\n",
    "        ax[3].set_title(f'Ar1 Latency Entropy - Best alpha = {ar1_latency_alpha_entropy:.3f}')\n",
    "    \n",
    "        # 标准差\n",
    "        ax[4].hist(np.exp(-iid_latency_alpha_std * latency_data_iid[iid_index_std, :]), bins=30, density=True, alpha=0.6, color='g')\n",
    "        ax[4].set_title(f'Iid Latency Std - Best alpha = {iid_latency_alpha_std:.3f}')\n",
    "        ax[5].hist(np.exp(-ar1_latency_alpha_std * latency_data_ar1[ar1_index_std, :]), bins=30, density=True, alpha=0.6, color='g')\n",
    "        ax[5].set_title(f'Ar1 Latency Std - Best alpha = {ar1_latency_alpha_std:.3f}')\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return iid_latency_alpha_kl, ar1_latency_alpha_std\n",
    "\n",
    "    def _generate_means(self, mean: float, std: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        生成节点的平均负载或延迟数据。\n",
    "\n",
    "        :return: 包含节点平均负载或延迟的 numpy 数组\n",
    "        \"\"\"\n",
    "        return np.random.normal(mean, std, size=(self.N,))\n",
    "\n",
    "    def _generate_iid_data(self, std: float, means: np.ndarray, data_type: str = 'load') -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        生成 IID 数据。\n",
    "\n",
    "        :return: 生成的 IID 数据和每个节点的均值\n",
    "        \"\"\"\n",
    "        if data_type == 'load':\n",
    "            loads = np.array([\n",
    "                np.random.normal(\n",
    "                    loc=means[i],\n",
    "                    scale=std,\n",
    "                    size=self.T\n",
    "                ) for i in range(self.N)\n",
    "            ])\n",
    "        elif data_type == 'latency':\n",
    "            loads = np.array([\n",
    "                np.random.exponential(\n",
    "                    scale=means[i],\n",
    "                    size=self.T\n",
    "                ) for i in range(self.N)\n",
    "            ])\n",
    "        return loads, np.mean(loads, axis=1)\n",
    "\n",
    "    def _generate_ar1_data(self, theta: float, means: np.ndarray, data_type: str = 'load') -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        生成 AR(1) 数据。\n",
    "\n",
    "        :return: 生成的 AR(1) 数据和每个节点的均值\n",
    "        \"\"\"\n",
    "        loads = np.zeros((self.N, self.T))\n",
    "\n",
    "        for i in range(self.N):\n",
    "            if data_type == 'load':\n",
    "                # 生成 load 数据的 AR(1)\n",
    "                ar1 = np.zeros(self.T)\n",
    "                ar1[0] = means[i]\n",
    "                for t in range(1, self.T):\n",
    "                    ar1[t] = theta * ar1[t-1] + (1 - theta) * np.random.normal(means[i], np.sqrt(self.node_load_iid_std))\n",
    "                loads[i] = ar1\n",
    "\n",
    "            elif data_type == 'latency':\n",
    "                # 生成 latency 数据的 AR(1)，加入不同的噪声项\n",
    "                ar1 = np.zeros(self.T)\n",
    "                ar1[0] = means[i]\n",
    "                for t in range(1, self.T):\n",
    "                    ar1[t] = theta * ar1[t-1] + (1 - theta) * np.random.exponential(means[i])\n",
    "                loads[i] = ar1\n",
    "\n",
    "        return loads, np.mean(loads, axis=1)\n",
    "\n",
    "    def _save_data(self) -> None:\n",
    "        \"\"\"\n",
    "        将生成的数据保存为 CSV 文件。\n",
    "        \"\"\"\n",
    "        pd.DataFrame(self.load_iid).to_csv(load_latency_original_csv_path/'load_iid_data.csv', index=False)\n",
    "        pd.DataFrame(self.load_ar1).to_csv(load_latency_original_csv_path/'load_ar1_data.csv', index=False)\n",
    "        pd.DataFrame(self.latency_iid).to_csv(load_latency_original_csv_path/'latency_iid_data.csv', index=False)\n",
    "        pd.DataFrame(self.latency_ar1).to_csv(load_latency_original_csv_path/'latency_ar1_data.csv', index=False)\n",
    "\n",
    "    def print_data_generate_info(self) -> None:\n",
    "        \"\"\"\n",
    "        打印生成的数据的基本信息。\n",
    "        \"\"\"\n",
    "        print(f'---------- Data Generation Info ----------')\n",
    "        print(f'Number of Nodes: {self.N}')\n",
    "        print(f'Number of Time Steps: {self.T}')\n",
    "        print(f'Number of Training and Validation Time Steps: {self.T_train_val}')\n",
    "        print(f'Number of Testing Time Steps: {self.T_test}')\n",
    "        print(f'Node Load Mean Mean: {self.node_load_mean_mean}')\n",
    "        print(f'Node Load Mean Variance: {self.node_load_mean_std}')\n",
    "        print(f'Node Load IID Variance: {self.node_load_iid_std}')\n",
    "        print(f'Node Load AR1 Theta: {self.node_load_ar1_theta}')\n",
    "        print(f'Node Latency Mean Mean: {self.node_latency_mean_mean}')\n",
    "        print(f'Node Latency Mean Variance: {self.node_latency_mean_std}')\n",
    "        print(f'Node Latency AR1 Theta: {self.node_latency_ar1_theta}')\n",
    "        print(f'-----------------------------------------')\n",
    "\n",
    "\n",
    "    def plot_original_means(self) -> None:\n",
    "        \"\"\"\n",
    "        绘制生成的节点平均负载和延迟。\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(self.means_loads, marker='o', linestyle='-', color='b', label='means_load')\n",
    "        plt.plot(self.means_latencies, marker='x', linestyle='-', color='r', label='means_latency')\n",
    "        plt.title('Original Random Means of Nodes for Load and Latency')\n",
    "        plt.xlabel('Node')\n",
    "        plt.ylabel('Mean Value')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_combined_data(self, i: int) -> None:\n",
    "        \"\"\"\n",
    "        Combines and plots the IID and AR1 data for load and latency for all nodes.\n",
    "        The histograms in the two right columns are only for the i-th node,\n",
    "        while the AR1 time series line plots include all nodes. The column order is rearranged.\n",
    "\n",
    "        Parameters:\n",
    "        i (int): Index of the node to plot histograms for.\n",
    "        \"\"\"\n",
    "\n",
    "        fig, axs = plt.subplots(2, 5, figsize=(25, 10))\n",
    "\n",
    "        # KDE plot for each node's load IID data (left side)\n",
    "        for node_index in range(self.N):\n",
    "            sns.kdeplot(self.load_iid[node_index], ax=axs[0, 0], label=f'Node {node_index+1}')\n",
    "        axs[0, 0].set_title(\"Load IID Data Distribution - All Nodes\")\n",
    "        axs[0, 0].legend()\n",
    "\n",
    "        # Time series plot of load IID for all nodes\n",
    "        axs[0, 1].plot(self.load_iid.T, alpha=0.6)\n",
    "        axs[0, 1].set_title(\"Load IID Time Series - All Nodes\")\n",
    "\n",
    "        # Histogram of IID data for load (middle, only for the i-th node)\n",
    "        axs[0, 2].hist(self.load_iid[i], bins=30, color='blue', alpha=0.7)\n",
    "        axs[0, 2].set_title(f\"Node {i+1} Load IID Histogram\")\n",
    "\n",
    "        # Time series plot of load AR1 for all nodes (next to the histogram)\n",
    "        axs[0, 3].plot(self.load_ar1.T, alpha=0.6)\n",
    "        axs[0, 3].set_title(\"Load AR1 Time Series - All Nodes\")\n",
    "\n",
    "        # Histogram of AR1 data for load (rightmost, only for the i-th node)\n",
    "        axs[0, 4].hist(self.load_ar1[i], bins=30, color='orange', alpha=0.7)\n",
    "        axs[0, 4].set_title(f\"Node {i+1} Load AR1 Histogram\")\n",
    "\n",
    "        # KDE plot for each node's latency IID data (left side)\n",
    "        for node_index in range(self.N):\n",
    "            sns.kdeplot(self.latency_iid[node_index], ax=axs[1, 0], label=f'Node {node_index+1}')\n",
    "        axs[1, 0].set_title(\"Latency IID Data Distribution - All Nodes\")\n",
    "        axs[1, 0].legend()\n",
    "\n",
    "        # Time series plot of latency IID for all nodes\n",
    "        axs[1, 1].plot(self.latency_iid.T, alpha=0.6)\n",
    "        axs[1, 1].set_title(\"Latency IID Time Series - All Nodes\")\n",
    "\n",
    "        # Histogram of IID data for latency (middle, only for the i-th node)\n",
    "        axs[1, 2].hist(self.latency_iid[i], bins=30, color='green', alpha=0.7)\n",
    "        axs[1, 2].set_title(f\"Node {i+1} Latency IID Histogram\")\n",
    "\n",
    "        # Time series plot of latency AR1 for all nodes (next to the histogram)\n",
    "        axs[1, 3].plot(self.latency_ar1.T, alpha=0.6)\n",
    "        axs[1, 3].set_title(\"Latency AR1 Time Series - All Nodes\")\n",
    "\n",
    "        # Histogram of AR1 data for latency (rightmost, only for the i-th node)\n",
    "        axs[1, 4].hist(self.latency_ar1[i], bins=30, color='red', alpha=0.7)\n",
    "        axs[1, 4].set_title(f\"Node {i+1} Latency AR1 Histogram\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'Combined_Figure_Reordered_Node_{i+1}.png')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_comparison(self) -> None:\n",
    "        \"\"\"\n",
    "        绘制 self.means_loads, self.load_mean_iid, self.load_mean_ar1,\n",
    "        self.means_latencies, self.latency_mean_iid, self.latency_mean_ar1 的对比图。\n",
    "        其中，latency 的曲线使用虚线，means 的、iid 的、ar1 的要有对应相似的表现。\n",
    "        \"\"\"\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        # 绘制 Load 数据\n",
    "        plt.plot(self.means_loads, marker='o', linestyle='-', color='blue', label='Load Means')\n",
    "        plt.plot(self.load_mean_iid, marker='x', linestyle='-', color='cyan', label='Load IID Mean')\n",
    "        plt.plot(self.load_mean_ar1, marker='s', linestyle='-', color='darkblue', label='Load AR1 Mean')\n",
    "\n",
    "        # 绘制 Latency 数据 (使用虚线)\n",
    "        plt.plot(self.means_latencies, marker='o', linestyle='--', color='red', label='Latency Means')\n",
    "        plt.plot(self.latency_mean_iid, marker='x', linestyle='--', color='orange', label='Latency IID Mean')\n",
    "        plt.plot(self.latency_mean_ar1, marker='s', linestyle='--', color='darkred', label='Latency AR1 Mean')\n",
    "\n",
    "        # 图例和标签\n",
    "        plt.title('Comparison of Means, IID Mean, and AR1 Mean for Load and Latency')\n",
    "        plt.xlabel('Node')\n",
    "        plt.ylabel('Mean Value')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "id": "207eeda17f07750f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class RewardDataCalculator:\n",
    "    def __init__(self, reward_parameters, if_save=False):\n",
    "        \n",
    "        # 加载 iid 数据\n",
    "        self.iid_load = pd.read_csv(load_latency_original_csv_path / 'load_iid_data.csv').values\n",
    "        self.iid_latency = pd.read_csv(load_latency_original_csv_path / 'latency_iid_data.csv').values\n",
    "\n",
    "        # 加载 ar1 数据\n",
    "        self.ar1_load = pd.read_csv(load_latency_original_csv_path / 'load_ar1_data.csv').values\n",
    "        self.ar1_latency = pd.read_csv(load_latency_original_csv_path / 'latency_ar1_data.csv').values\n",
    "\n",
    "        # 保存reward_parameters_slider的相关参数到self\n",
    "        self.iid_alpha_load_0= reward_parameters.iid.alpha_load_0\n",
    "        self.iid_alpha_latency_1 = reward_parameters.iid.alpha_latency_1\n",
    "\n",
    "        self.ar1_alpha_load_0 = reward_parameters.ar1.alpha_load_0\n",
    "        self.ar1_alpha_latency_1 = reward_parameters.ar1.alpha_latency_1\n",
    "\n",
    "        # 计算reward数据\n",
    "        self.iid_load_reward_0 = self.calculate_reward(self.iid_load, 'load_0')\n",
    "        self.iid_load_reward_1 = self.calculate_reward(self.iid_load, 'load_1')\n",
    "        self.iid_latency_reward_1 = self.calculate_reward(self.iid_latency, 'latency_1')\n",
    "\n",
    "        self.ar1_load_reward_0 = self.calculate_reward(self.ar1_load, 'load_0')\n",
    "        self.ar1_load_reward_1 = self.calculate_reward(self.ar1_load, 'load_1')\n",
    "        self.ar1_latency_reward_1 = self.calculate_reward(self.ar1_latency, 'latency_1')\n",
    "\n",
    "        # 保存reward数据\n",
    "        if if_save:\n",
    "            self.save_reward_data()\n",
    "\n",
    "        # 打印reward数据信息\n",
    "        self.print_info()\n",
    "\n",
    "        # 绘制reward数据\n",
    "        self.plot_reward_data()\n",
    "\n",
    "    def calculate_reward(self, data: np.ndarray, method: str) -> np.ndarray:\n",
    "        if method == 'load_0':\n",
    "            return self.iid_alpha_load_0 / (1 + data)\n",
    "\n",
    "        elif method == 'load_1':\n",
    "            inverted_data = 1 / (1 + data)\n",
    "            normalized_data = (inverted_data - inverted_data.min(axis=0)) / (inverted_data.max(axis=0) - inverted_data.min(axis=0))\n",
    "            return normalized_data\n",
    "\n",
    "        elif method == 'latency_1':\n",
    "            return np.exp(-self.iid_alpha_latency_1 * data)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    def save_reward_data(self):\n",
    "        np.save(rewards_npy_path/'iid_load_reward_0.npy', self.iid_load_reward_0)\n",
    "        np.save(rewards_npy_path/'iid_load_reward_1.npy', self.iid_load_reward_1)\n",
    "        np.save(rewards_npy_path/'iid_latency_reward_1.npy', self.iid_latency_reward_1)\n",
    "\n",
    "        np.save(rewards_npy_path/'ar1_load_reward_0.npy', self.ar1_load_reward_0)\n",
    "        np.save(rewards_npy_path/'ar1_load_reward_1.npy', self.ar1_load_reward_1)\n",
    "        np.save(rewards_npy_path/'ar1_latency_reward_1.npy', self.ar1_latency_reward_1)\n",
    "\n",
    "    def print_info(self):\n",
    "        print(f\"iid_load_reward_0.shape: {self.iid_load_reward_0.shape}\")\n",
    "        print(f\"iid_load_reward_1.shape: {self.iid_load_reward_1.shape}\")\n",
    "        print(f\"iid_latency_reward_1.shape: {self.iid_latency_reward_1.shape}\")\n",
    "\n",
    "        print(f\"ar1_load_reward_0.shape: {self.ar1_load_reward_0.shape}\")\n",
    "        print(f\"ar1_load_reward_1.shape: {self.ar1_load_reward_1.shape}\")\n",
    "        print(f\"ar1_latency_reward_1.shape: {self.ar1_latency_reward_1.shape}\")\n",
    "\n",
    "    def plot_reward_data(self, start_node=0, end_node=2):\n",
    "        \"\"\"\n",
    "        绘制指定节点范围的数据，包括折线图、均值图和直方图。\n",
    "\n",
    "        参数:\n",
    "        start_node (int): 要绘制的起始节点索引 (包含)。\n",
    "        end_node (int): 要绘制的结束节点索引 (包含)。\n",
    "        \"\"\"\n",
    "        # 绘制10*3个输出数据的折线图、直方图、均值图\n",
    "        fig, axs = plt.subplots(10, 3, figsize=(18, 30))\n",
    "\n",
    "        datasets = [\n",
    "            (\"Load IID Original\", self.iid_load),\n",
    "            (\"Load IID Reward 0\", self.iid_load_reward_0),\n",
    "            (\"Load IID Reward 1\", self.iid_load_reward_1),\n",
    "            (\"Latency IID Original\", self.iid_latency),\n",
    "            (\"Latency IID Reward 1\", self.iid_latency_reward_1),\n",
    "            (\"Load AR1 Original\", self.ar1_load),\n",
    "            (\"Load AR1 Reward 0\", self.ar1_load_reward_0),\n",
    "            (\"Load AR1 Reward 1\", self.ar1_load_reward_1),\n",
    "            (\"Latency AR1 Original\", self.ar1_latency),\n",
    "            (\"Latency AR1 Reward 1\", self.ar1_latency_reward_1)\n",
    "        ]\n",
    "\n",
    "        for idx, (title, data) in enumerate(datasets):\n",
    "            self.plot_single_data(axs, data[start_node:end_node+1], data, row=idx, title=title, ylabel='Value', start_node=start_node)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_single_data(self, axs, partial_data, full_data, row, title, ylabel, start_node):\n",
    "        \"\"\"\n",
    "        绘制单组数据的折线图、均值图和直方图。\n",
    "\n",
    "        参数:\n",
    "        axs (ndarray): 子图的轴数组。\n",
    "        partial_data (ndarray): 要绘制的部分数据（指定节点范围）。\n",
    "        full_data (ndarray): 用于绘制均值图的完整数据。\n",
    "        row (int): 在子图中的行索引。\n",
    "        title (str): 图表的标题。\n",
    "        ylabel (str): Y轴的标签。\n",
    "        start_node (int): 要绘制的起始节点索引 (用于标记节点标签)。\n",
    "        \"\"\"\n",
    "        # 绘制折线图\n",
    "        for i in range(partial_data.shape[0]):\n",
    "            axs[row, 0].plot(partial_data[i], label=f'Node {i + start_node}')\n",
    "        axs[row, 0].set_title(f\"{title} - Selected Nodes\")\n",
    "        axs[row, 0].set_xlabel('Time')\n",
    "        axs[row, 0].set_ylabel(ylabel)\n",
    "        axs[row, 0].legend()\n",
    "        axs[row, 0].grid(True)\n",
    "\n",
    "        # 绘制均值图 (使用全部节点)\n",
    "        mean_values = np.mean(full_data, axis=1)\n",
    "        axs[row, 1].plot(mean_values, marker='o', linestyle='-', color='b', label=f'Mean {ylabel} per Node')\n",
    "        axs[row, 1].set_title(f'{title} - Mean Values (All Nodes)')\n",
    "        axs[row, 1].set_xlabel('Node')\n",
    "        axs[row, 1].set_ylabel(f'Mean {ylabel}')\n",
    "        axs[row, 1].legend()\n",
    "        axs[row, 1].grid(True)\n",
    "\n",
    "        y_max = mean_values.max()\n",
    "        y_min = mean_values.min()\n",
    "        range_value = y_max - y_min\n",
    "\n",
    "        axs[row, 1].text(len(mean_values) - 1, (y_max + y_min) / 2,\n",
    "                         f'Range: {range_value:.3f}',\n",
    "                         ha='right', va='center', fontsize=10, color='red')\n",
    "        axs[row, 1].hlines([y_min, y_max], xmin=0, xmax=len(mean_values) - 1, colors='red', linestyles='--', label='Range')\n",
    "        axs[row, 1].legend()\n",
    "\n",
    "        # 绘制直方图\n",
    "        for i in range(partial_data.shape[0]):\n",
    "            axs[row, 2].hist(partial_data[i].flatten(), bins=30, alpha=0.2, label=f'Node {i + start_node}')\n",
    "        axs[row, 2].set_title(f'{title} - Histogram (Selected Nodes)')\n",
    "        axs[row, 2].set_xlabel(f'{ylabel} Value')\n",
    "        axs[row, 2].set_ylabel('Frequency')\n",
    "        axs[row, 2].legend()\n",
    "        axs[row, 2].grid(True)\n"
   ],
   "id": "f4d6af05817a4581",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class RewardDataManager:\n",
    "    def __init__(self, config: DictConfig) -> None:\n",
    "        self.config = config\n",
    "\n",
    "        # 加载数据\n",
    "        # iid 数据\n",
    "        self.iid_load = pd.read_csv(load_latency_original_csv_path / 'load_iid_data.csv').values\n",
    "        self.iid_load_reward_0 = np.load(rewards_npy_path / 'iid_load_reward_0.npy')\n",
    "        self.iid_load_reward_1 = np.load(rewards_npy_path / 'iid_load_reward_1.npy')\n",
    "        self.iid_latency = pd.read_csv(load_latency_original_csv_path / 'latency_iid_data.csv').values\n",
    "        self.iid_latency_reward_1 = np.load(rewards_npy_path / 'iid_latency_reward_1.npy')\n",
    "\n",
    "        # ar1 数据\n",
    "        self.ar1_load = pd.read_csv(load_latency_original_csv_path / 'load_ar1_data.csv').values\n",
    "        self.ar1_load_reward_0 = np.load(rewards_npy_path / 'ar1_load_reward_0.npy')\n",
    "        self.ar1_load_reward_1 = np.load(rewards_npy_path / 'ar1_load_reward_1.npy')\n",
    "        self.ar1_latency = pd.read_csv(load_latency_original_csv_path / 'latency_ar1_data.csv').values\n",
    "        self.ar1_latency_reward_1 = np.load(rewards_npy_path / 'ar1_latency_reward_1.npy')\n",
    "        \n",
    "    def print_info(self):\n",
    "        print(f\"---------- Reward Data Info ----------\")\n",
    "        print(f\"iid_load_original.shape: {self.iid_load.shape}\")\n",
    "        print(f\"iid_load_reward_0.shape: {self.iid_load_reward_0.shape}\")\n",
    "        print(f\"iid_load_reward_1.shape: {self.iid_load_reward_1.shape}\")\n",
    "        print(f\"iid_latency_original.shape: {self.iid_latency.shape}\")\n",
    "        print(f\"iid_latency_reward_1.shape: {self.iid_latency_reward_1.shape}\")\n",
    "    \n",
    "        print(f\"ar1_load_original.shape: {self.ar1_load.shape}\")\n",
    "        print(f\"ar1_load_reward_0.shape: {self.ar1_load_reward_0.shape}\")\n",
    "        print(f\"ar1_load_reward_1.shape: {self.ar1_load_reward_1.shape}\")\n",
    "        print(f\"ar1_latency_original.shape: {self.ar1_latency.shape}\")\n",
    "        print(f\"ar1_latency_reward_1.shape: {self.ar1_latency_reward_1.shape}\")\n",
    "        print(f\"--------------------------------------\")\n",
    "    \n",
    "    def plot_reward_data(self, start_node=0, end_node=2):\n",
    "        \"\"\"\n",
    "        绘制指定节点范围的数据，包括折线图、均值图和直方图。\n",
    "    \n",
    "        参数:\n",
    "        start_node (int): 要绘制的起始节点索引 (包含)。\n",
    "        end_node (int): 要绘制的结束节点索引 (包含)。\n",
    "        \"\"\"\n",
    "        # 绘制10*3个输出数据的折线图、直方图、均值图\n",
    "        fig, axs = plt.subplots(10, 3, figsize=(18, 30))\n",
    "    \n",
    "        datasets = [\n",
    "            (\"Load IID Original\", self.iid_load),\n",
    "            (\"Load IID Reward 0\", self.iid_load_reward_0),\n",
    "            (\"Load IID Reward 1\", self.iid_load_reward_1),\n",
    "            (\"Latency IID Original\", self.iid_latency),\n",
    "            (\"Latency IID Reward 1\", self.iid_latency_reward_1),\n",
    "            (\"Load AR1 Original\", self.ar1_load),\n",
    "            (\"Load AR1 Reward 0\", self.ar1_load_reward_0),\n",
    "            (\"Load AR1 Reward 1\", self.ar1_load_reward_1),\n",
    "            (\"Latency AR1 Original\", self.ar1_latency),\n",
    "            (\"Latency AR1 Reward 1\", self.ar1_latency_reward_1)\n",
    "        ]\n",
    "    \n",
    "        for idx, (title, data) in enumerate(datasets):\n",
    "            self.plot_single_data(axs, data[start_node:end_node+1], data, row=idx, title=title, ylabel='Value', start_node=start_node)\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_single_data(self, axs, partial_data, full_data, row, title, ylabel, start_node):\n",
    "        \"\"\"\n",
    "        绘制单组数据的折线图、均值图和直方图。\n",
    "    \n",
    "        参数:\n",
    "        axs (ndarray): 子图的轴数组。\n",
    "        partial_data (ndarray): 要绘制的部分数据（指定节点范围）。\n",
    "        full_data (ndarray): 用于绘制均值图的完整数据。\n",
    "        row (int): 在子图中的行索引。\n",
    "        title (str): 图表的标题。\n",
    "        ylabel (str): Y轴的标签。\n",
    "        start_node (int): 要绘制的起始节点索引 (用于标记节点标签)。\n",
    "        \"\"\"\n",
    "        # 绘制折线图\n",
    "        for i in range(partial_data.shape[0]):\n",
    "            axs[row, 0].plot(partial_data[i], label=f'Node {i + start_node}')\n",
    "        axs[row, 0].set_title(f\"{title} - Selected Nodes\")\n",
    "        axs[row, 0].set_xlabel('Time')\n",
    "        axs[row, 0].set_ylabel(ylabel)\n",
    "        axs[row, 0].legend()\n",
    "        axs[row, 0].grid(True)\n",
    "    \n",
    "        # 绘制均值图 (使用全部节点)\n",
    "        mean_values = np.mean(full_data, axis=1)\n",
    "        axs[row, 1].plot(mean_values, marker='o', linestyle='-', color='b', label=f'Mean {ylabel} per Node')\n",
    "        axs[row, 1].set_title(f'{title} - Mean Values (All Nodes)')\n",
    "        axs[row, 1].set_xlabel('Node')\n",
    "        axs[row, 1].set_ylabel(f'Mean {ylabel}')\n",
    "        axs[row, 1].legend()\n",
    "        axs[row, 1].grid(True)\n",
    "    \n",
    "        y_max = mean_values.max()\n",
    "        y_min = mean_values.min()\n",
    "        range_value = y_max - y_min\n",
    "    \n",
    "        axs[row, 1].text(len(mean_values) - 1, (y_max + y_min) / 2,\n",
    "                         f'Range: {range_value:.3f}',\n",
    "                         ha='right', va='center', fontsize=10, color='red')\n",
    "        axs[row, 1].hlines([y_min, y_max], xmin=0, xmax=len(mean_values) - 1, colors='red', linestyles='--', label='Range')\n",
    "        axs[row, 1].legend()\n",
    "    \n",
    "        # 绘制直方图\n",
    "        for i in range(partial_data.shape[0]):\n",
    "            axs[row, 2].hist(partial_data[i].flatten(), bins=30, alpha=0.2, label=f'Node {i + start_node}')\n",
    "        axs[row, 2].set_title(f'{title} - Histogram (Selected Nodes)')\n",
    "        axs[row, 2].set_xlabel(f'{ylabel} Value')\n",
    "        axs[row, 2].set_ylabel('Frequency')\n",
    "        axs[row, 2].legend()\n",
    "        axs[row, 2].grid(True)\n"
   ],
   "id": "2a07eae90f38869d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class DataManager:\n",
    "    def __init__(self, config: DictConfig, data_type: str) -> None:\n",
    "        \"\"\"\n",
    "        初始化 TrainValidManage 类，接受一个 omegaconf 的 DictConfig 对象作为配置，并将\n",
    "        所需的配置项提取为类属性。\n",
    "\n",
    "        :param config: 配置文件，使用 omegaconf 加载的 DictConfig 对象\n",
    "        \"\"\"\n",
    "        # 提取并保存配置项\n",
    "        base_config = config.base\n",
    "        exp4_config = config.exp4\n",
    "\n",
    "        # self.data_type = base_config.data_type  # 从 base_config 提取 data_type\n",
    "        self.data_type = data_type\n",
    "        self.device = exp4_config.device  # 从 exp4_config 提取设备信息\n",
    "        self.batch_size = exp4_config.batch_size\n",
    "        self.num_workers = exp4_config.num_workers\n",
    "        self.N = base_config.N\n",
    "        self.T = base_config.T\n",
    "        self.T_train = base_config.T_train\n",
    "        self.T_val = base_config.T_val\n",
    "        self.train_ratio = base_config.train_ratio\n",
    "        self.T_train_val = base_config.T_train_val\n",
    "        self.T_test = base_config.T_test\n",
    "        self.seq_length = exp4_config.seq_length\n",
    "\n",
    "        # 加载数据\n",
    "        # iid 数据\n",
    "        self.iid_load = pd.read_csv(load_latency_original_csv_path / 'load_iid_data.csv').values\n",
    "        self.iid_latency = pd.read_csv(load_latency_original_csv_path / 'latency_iid_data.csv').values\n",
    "        \n",
    "        # ar1 数据\n",
    "        self.ar1_load = pd.read_csv(load_latency_original_csv_path / 'load_ar1_data.csv').values\n",
    "        self.ar1_latency = pd.read_csv(load_latency_original_csv_path / 'latency_ar1_data.csv').values\n",
    "        \n",
    "        # 根据数据类型选择数据\n",
    "        match self.data_type:\n",
    "            case 'iid_load_pred':\n",
    "                self.data_np = self.iid_load\n",
    "            case 'ar1_load_pred':\n",
    "                self.data_np = self.ar1_load\n",
    "            case 'iid_latency_pred':\n",
    "                self.data_np = self.iid_latency\n",
    "            case 'ar1_latency_pred':\n",
    "                self.data_np = self.ar1_latency\n",
    "            case _:\n",
    "                raise ValueError(f\"Unknown data_type: {self.data_type}\")\n",
    "\n",
    "        # 将数据转换为 PyTorch 张量\n",
    "        self.data_tensor = torch.tensor(self.data_np, device=self.device, dtype=torch.float32)\n",
    "\n",
    "        # 划分np.array的训练集、验证集和测试集\n",
    "        self.train_val_data_np = self.data_np[:, :self.T_train_val]\n",
    "        self.train_data_np = self.data_np[:, :self.T_train]\n",
    "        self.val_data_np = self.data_np[:, self.T_train:self.T_train_val]\n",
    "        self.test_data_np = self.data_np[:, self.T_train_val:]\n",
    "\n",
    "        # 储存tensor的训练集、验证集和测试集\n",
    "        self.train_val_data_tensor = torch.tensor(self.train_val_data_np, device=self.device, dtype=torch.float32)\n",
    "        self.train_data_tensor = torch.tensor(self.train_data_np, device=self.device, dtype=torch.float32)\n",
    "        self.val_data_tensor = torch.tensor(self.val_data_np, device=self.device, dtype=torch.float32)\n",
    "        self.test_data_tensor = torch.tensor(self.test_data_np, device=self.device, dtype=torch.float32)\n",
    "\n",
    "        # 创建训练集、验证集、训练验证集的序列数据\n",
    "        self.train_val_x, self.train_val_y = self._create_sequences(self.data_np, 'train_val')\n",
    "        self.train_x, self.train_y = self._create_sequences(self.data_np, 'train')\n",
    "        self.val_x, self.val_y = self._create_sequences(self.data_np, 'val')\n",
    "\n",
    "        # 创建TensorDataset，用于创建DataLoader\n",
    "        self.train_val_dataset = TensorDataset(self.train_val_x, self.train_val_y)\n",
    "        self.train_dataset = TensorDataset(self.train_x, self.train_y)\n",
    "        self.val_dataset = TensorDataset(self.val_x, self.val_y)\n",
    "\n",
    "        # 创建数据加载器\n",
    "        self.train_val_dataloader = DataLoader(self.train_val_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "        self.train_dataloader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "        self.val_dataloader = DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "        # 创建GNN的边索引\n",
    "        self.edge_index_tensor = torch.tensor(\n",
    "            np.array([(i, j) for i in range(self.N) for j in range(self.N)]).T,\n",
    "            dtype=torch.long)  # 默认全连接图\n",
    "\n",
    "        # 打印信息\n",
    "        self.print_train_valid_info()\n",
    "\n",
    "    def _create_sequences(self, data: np.ndarray, split_type: str) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        根据数据创建序列数据。\n",
    "\n",
    "        :param data: 输入的numpy数组数据\n",
    "        :param split_type: 数据的切分类型（'train', 'val', 'train_val'）\n",
    "        :return: 生成的输入序列张量和目标序列张量\n",
    "        \"\"\"\n",
    "        x, y = [], []\n",
    "\n",
    "        if split_type == 'train':\n",
    "            # 训练集，从1到8000 (用1-20预测21)\n",
    "            for i in range(self.seq_length, self.T_train):\n",
    "                x.append(data[:, i - self.seq_length:i].T)\n",
    "                y.append(data[:, i])\n",
    "\n",
    "        elif split_type == 'val':\n",
    "            # 验证集，从8001到10000 (用7981-8000预测8001)\n",
    "            for i in range(self.T_train, self.T_train_val):\n",
    "                x.append(data[:, i - self.seq_length:i].T)\n",
    "                y.append(data[:, i])\n",
    "\n",
    "        elif split_type == 'train_val':\n",
    "            # 训练验证集，从1到10000 (用1-20预测21)\n",
    "            for i in range(self.seq_length, self.T_train_val):\n",
    "                x.append(data[:, i - self.seq_length:i].T)\n",
    "                y.append(data[:, i])\n",
    "\n",
    "        return torch.tensor(np.array(x)), torch.tensor(np.array(y))\n",
    "\n",
    "    def print_train_valid_info(self) -> None:\n",
    "        \"\"\"\n",
    "        打印训练和验证数据的信息。\n",
    "        \"\"\"\n",
    "        print(f'================= Data Info =================')\n",
    "        print(f'----------------- Base Info-----------------')\n",
    "        print(f'data_type: {self.data_type}')\n",
    "        print(f'device: {self.device}')\n",
    "        print(f'batch_size: {self.batch_size}')\n",
    "        print(f'num_workers: {self.num_workers}')\n",
    "        print(f'N: {self.N}')\n",
    "        print(f'T: {self.T}')\n",
    "        print(f'T_train: {self.T_train}')\n",
    "        print(f'T_val: {self.T_val}')\n",
    "        print(f'train_ratio: {self.train_ratio}')\n",
    "        print(f'T_train_val: {self.T_train_val}')\n",
    "        print(f'T_test: {self.T_test}')\n",
    "        print(f'seq_length: {self.seq_length}')\n",
    "\n",
    "        print(f'----------------- Data Info -----------------')\n",
    "        print(f'iid_load_pred.shape: {self.iid_load.shape}')\n",
    "        print(f'ar1_load_pred.shape: {self.ar1_load.shape}')\n",
    "        print(f'iid_latency_pred.shape: {self.iid_latency.shape}')\n",
    "        print(f'ar1_latency_pred.shape: {self.ar1_latency.shape}')\n",
    "        print(f'data_np.shape: {self.data_np.shape}')\n",
    "        print(f'data_tensor.shape: {self.data_tensor.shape}')\n",
    "\n",
    "        print(f'----------------- Split Info -----------------')\n",
    "        print('train_val_data_np.shape:', self.train_val_data_np.shape)\n",
    "        print('train_data_np.shape:', self.train_data_np.shape)\n",
    "        print('val_data_np.shape:', self.val_data_np.shape)\n",
    "        print('test_data_np.shape:', self.test_data_np.shape)\n",
    "        print('train_val_data_tensor.shape:', self.train_val_data_tensor.shape)\n",
    "        print('train_data_tensor.shape:', self.train_data_tensor.shape)\n",
    "        print('val_data_tensor.shape:', self.val_data_tensor.shape)\n",
    "        print('test_data_tensor.shape:', self.test_data_tensor.shape)\n",
    "\n",
    "        print(f'----------------- Sequence Info -----------------')\n",
    "        print('train_val_x.shape:', self.train_val_x.shape)\n",
    "        print('train_val_y.shape:', self.train_val_y.shape)\n",
    "        print('train_x.shape:', self.train_x.shape)\n",
    "        print('train_y.shape:', self.train_y.shape)\n",
    "        print('val_x.shape:', self.val_x.shape)\n",
    "        print('val_y.shape:', self.val_y.shape)\n",
    "\n",
    "        print(f'----------------- DataLoader Info -----------------')\n",
    "        self.print_dataloader_info(self.train_val_dataloader, 'Train-Val')\n",
    "        self.print_dataloader_info(self.train_dataloader, 'Train')\n",
    "        self.print_dataloader_info(self.val_dataloader, 'Val')\n",
    "\n",
    "        print(f'----------------- Edge Index Info -----------------')\n",
    "        print('edge_index_tensor.shape:', self.edge_index_tensor.shape)\n",
    "\n",
    "        print(f'===================== End Info =====================')\n",
    "\n",
    "    def print_dataloader_info(self, dataloader: DataLoader, title: str) -> None:\n",
    "        \"\"\"\n",
    "        打印 DataLoader 的信息。\n",
    "\n",
    "        :param dataloader: DataLoader 对象\n",
    "        :param title: 信息标题\n",
    "        \"\"\"\n",
    "        print(f'{\"-\"*10} {title} Dataloader Info {\"-\"*10}')\n",
    "\n",
    "        # 打印头部行，展示 min/max 和 shape 信息\n",
    "        print(f'{\"Batch\":<10} {\"x.min\":<8} {\"x.max\":<8} {\"y.min\":<8} {\"y.max\":<8} {\"x.shape:torch.Size\":<18} {\"y.shape:torch.Size\":<18}')\n",
    "\n",
    "        # 打印每个批次的信息\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            if i % 30 == 0 or i == len(dataloader) - 1:\n",
    "                x_shape_str = str(list(x.shape))  # 使用 list 来缩短 shape 显示\n",
    "                y_shape_str = str(list(y.shape))\n",
    "\n",
    "                print(f'{i + 1:>5}/{len(dataloader):<5} '\n",
    "                      f'{x.min():<8.4f} {x.max():<8.4f} '\n",
    "                      f'{y.min():<8.4f} {y.max():<8.4f} '\n",
    "                      f'{x_shape_str:<18} {y_shape_str:<18}')\n",
    "\n",
    "    def plot_range_data(self, data: np.ndarray, start: int = None, end: int = None, title: str = 'Load Data') -> None:\n",
    "        \"\"\"\n",
    "        绘制指定范围内的数据。\n",
    "\n",
    "        :param data: 输入数据\n",
    "        :param start: 开始时间步，默认为0\n",
    "        :param end: 结束时间步，默认为数据结束\n",
    "        :param title: 图像标题\n",
    "        \"\"\"\n",
    "        start = 0 if start is None else start\n",
    "        end = data.shape[1] if end is None else end\n",
    "\n",
    "        time_steps = np.arange(start, end)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for i in range(data.shape[0]):\n",
    "            plt.plot(time_steps, data[i, start:end], label=f'Node {i}')\n",
    "        plt.title(f'{title} - Nodes {0}-{data.shape[0]}')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Load')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ],
   "id": "4d18a9a6be12921",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff504e9955b63577",
   "metadata": {},
   "source": [
    "def manage_and_save_data(config: DictConfig, data_type: str, plot_start_node: int=0, plot_end_node: int=3) -> None:\n",
    "    \"\"\"\n",
    "    生成数据，绘图，并保存数据管理对象。\n",
    "    \"\"\"\n",
    "    \n",
    "    if data_type in ['iid_load_pred', 'ar1_load_pred', 'iid_latency_pred', 'ar1_latency_pred']:\n",
    "        # 数据生成\n",
    "        data_manager = DataManager(config, data_type)\n",
    "    \n",
    "        # 绘图\n",
    "        data_manager.plot_range_data(data_manager.data_np[plot_start_node:plot_end_node, :], title=f'{data_type} Data')\n",
    "    \n",
    "    elif data_type == 'reward':\n",
    "        # 计算reward数据\n",
    "        RewardDataCalculator(config.data_generation.reward_parameters, if_save=True)\n",
    "        data_manager = RewardDataManager(config)\n",
    "\n",
    "    # 保存数据\n",
    "    with open(models_pkl_path/f'{data_type}_data_manager.pkl', 'wb') as f:\n",
    "        pickle.dump(data_manager, f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def config_manager(if_print=True) -> DictConfig:\n",
    "    \"\"\"\n",
    "    管理和创建所有配置。\n",
    "    \"\"\"\n",
    "    config_path = '/home/alex4060/PythonProject/MScProject/MScProject/config/config.yaml'\n",
    "\n",
    "    # 加载 config.yaml 文件\n",
    "    config = OmegaConf.load(config_path)\n",
    "\n",
    "    if if_print:\n",
    "        # 打印完整的配置内容\n",
    "        print(f'---------- Config Info ----------')\n",
    "        print(OmegaConf.to_yaml(config))\n",
    "        print(f'----------- config End -----------\\n')\n",
    "    \n",
    "    return config\n"
   ],
   "id": "b78e7c257f51e590",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def path_manager(config: DictConfig) -> tuple[Path, Path, Path, Path, Path]:\n",
    "    \"\"\"\n",
    "    管理和创建所有路径。\n",
    "    \"\"\"\n",
    "    global_path = Path(config.path.global_path)\n",
    "    data_path = global_path / 'Data'\n",
    "    load_latency_original_csv_path = data_path / 'load_latency_original_csv'\n",
    "    rewards_npy_path = data_path / 'rewards_npy'\n",
    "    models_pkl_path = data_path / 'models_pkl'\n",
    "    # 创建所有路径（如果路径不存在）\n",
    "    for path in [global_path, data_path, load_latency_original_csv_path, rewards_npy_path, models_pkl_path]:\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 打印全局路径和数据路径\n",
    "    print(f'---------- Path Info ----------')\n",
    "    print(f'Global Path: {global_path}')\n",
    "    print(f'Data Path: {data_path}')\n",
    "    print(f'Load Latency Original CSV Path: {load_latency_original_csv_path}')\n",
    "    print(f'Rewards NPY Path: {rewards_npy_path}')\n",
    "    print(f'Models PKL Path: {models_pkl_path}')\n",
    "    print(f'----------- Path End -----------')\n",
    "        \n",
    "    return global_path, data_path, load_latency_original_csv_path, rewards_npy_path, models_pkl_path"
   ],
   "id": "5e33bf91b6eb4a2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def import_data_manager(models_pkl_path, data_type: str, if_print=False) -> DataManager:\n",
    "    \"\"\"\n",
    "    从Pickle文件中导入数据管理对象。\n",
    "\n",
    "    # 示例调用\n",
    "    iid_load_data_manager = import_data_manager(models_pkl_path, 'iid_load_pred')\n",
    "    ar1_load_data_manager = import_data_manager(models_pkl_path, 'ar1_load_pred')\n",
    "    iid_latency_data_manager = import_data_manager(models_pkl_path, 'iid_latency_pred')\n",
    "    ar1_latency_data_manager = import_data_manager(models_pkl_path, 'ar1_latency_pred')\n",
    "    reward_data_manager = import_data_manager(models_pkl_path, 'reward')\n",
    "\n",
    "    # 绘制数据\n",
    "    iid_load_iid_data_manage.plot_range_data(load_iid_data_manage.data_np[:3, :], title='Load IID Data')\n",
    "    ar1_load_ar1_data_manage.plot_range_data(load_ar1_data_manage.data_np[:3, :], title='Load AR(1) Data')\n",
    "    iid_latency_idata_manage.plot_range_data(latency_iid_data_manage.data_np[:3, :], title='Latency IID Data')\n",
    "    ar1_latency_data_manager.plot_range_data(latency_ar1_data_manage.data_np[:3, :], title='Latency AR(1) Data')\n",
    "    reward_data_manager.plot_reward_data()\n",
    "    \"\"\"\n",
    "    file_path = models_pkl_path / f'{data_type}_data_manager.pkl'\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data_manager = pickle.load(f)\n",
    "\n",
    "    if if_print:\n",
    "        if data_type in ['iid_load_pred', 'ar1_load_pred', 'iid_latency_pred', 'ar1_latency_pred']:\n",
    "            data_manager.plot_range_data(data_manager.data_np[:3, :], title='data_type')\n",
    "        elif data_type == 'reward':\n",
    "            data_manager.print_info()\n",
    "            data_manager.plot_reward_data()\n",
    "\n",
    "    return data_manager\n"
   ],
   "id": "99237b33c88eb798"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    # 配置管理\n",
    "    config = config_manager()\n",
    "\n",
    "    # 路径管理\n",
    "    global_path, data_path, load_latency_original_csv_path, rewards_npy_path, models_pkl_path = path_manager(config)\n",
    "\n",
    "\n",
    "\n",
    "    # iid/ar load/latency 数据生成\n",
    "    # DataGenerator(config, if_save=True)\n",
    "    # 此步执行完之后，手动调整config.yaml中的data_generation.reward_parameters的参数，再继续执行下面的代码，尤其是manage_and_save_data(config, 'reward')。\n",
    "\n",
    "    # EXP4 算法的专家系统的预测值管理器\n",
    "    # exp4_data_manager = Exp4DataManager(config, data_path)\n",
    "    \n",
    "    # 数据管理\n",
    "    # manage_and_save_data(config, 'iid_load_pred', 0, 3)\n",
    "    # manage_and_save_data(config, 'ar1_load_pred', 0, 3)\n",
    "    # manage_and_save_data(config, 'iid_latency_pred', 0, 3)\n",
    "    # manage_and_save_data(config, 'ar1_latency_pred', 0, 3)\n",
    "\n",
    "    # manage_and_save_data(config, 'reward')"
   ],
   "id": "1c85cb08bc3ad8a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "530b2126ed58eee7",
   "metadata": {},
   "source": "# manage_and_save_data(config, 'reward')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "51817da94c7b35eb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
