{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83261547ded4d600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T01:54:28.049402Z",
     "start_time": "2024-08-26T01:54:27.977456Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots  # 确保导入 make_subplots\n",
    "from ipywidgets import interactive, interact, FloatSlider, ToggleButtons, HBox, VBox, Layout, IntSlider\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from DataInit import DataManager, RewardDataManager\n",
    "import DataInit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T01:54:28.082726Z",
     "start_time": "2024-08-26T01:54:28.056295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Config Info ----------\n",
      "path:\n",
      "  global_path: E:/Study in the UK/Project/MScProject\n",
      "base:\n",
      "  'N': 10\n",
      "  T: 11000\n",
      "  T_train_val: 10000\n",
      "  train_ratio: 0.8\n",
      "  T_train: 8000\n",
      "  T_val: 2000\n",
      "  T_test: 1000\n",
      "  lambda_load: 0.5\n",
      "  top_k:\n",
      "  - 1\n",
      "  - 2\n",
      "  - 3\n",
      "  - 4\n",
      "  - 5\n",
      "data_generation:\n",
      "  load_data:\n",
      "    node_load_mean_mean: 50.0\n",
      "    node_load_mean_var: 10.0\n",
      "    node_load_iid_var: 5.0\n",
      "    node_load_ar1_theta: 0.9\n",
      "  latency_data:\n",
      "    node_latency_mean_mean: 30.0\n",
      "    node_latency_mean_var: 10.0\n",
      "    node_latency_ar1_theta: 0.9\n",
      "  reward_parameters:\n",
      "    iid:\n",
      "      alpha_load_0: 40.0\n",
      "      alpha_latency_1: 0.041\n",
      "    ar1:\n",
      "      alpha_load_0: 40.0\n",
      "      alpha_latency_1: 0.041\n",
      "  reward_parameters_slider:\n",
      "    alpha_load_0:\n",
      "      value: 1.0\n",
      "      min: 0.001\n",
      "      max: 40.0\n",
      "      step: 0.01\n",
      "      description: alpha_load_0\n",
      "    alpha_latency_0:\n",
      "      value: 1.0\n",
      "      min: 0.001\n",
      "      max: 6.0\n",
      "      step: 0.01\n",
      "      description: alpha_latency_0\n",
      "    alpha_latency_1:\n",
      "      value: 0.5\n",
      "      min: 0.0001\n",
      "      max: 0.5\n",
      "      step: 0.001\n",
      "      description: alpha_latency_1\n",
      "epsilon_greedy:\n",
      "  dynamic_plot:\n",
      "    epsilon_min: 0.001\n",
      "    epsilon_max: 0.5\n",
      "    epsilon_step: 0.01\n",
      "    epsilon_default_value: 0.1\n",
      "  evaluation:\n",
      "    epsilon_min: 0.0001\n",
      "    epsilon_max: 0.2001\n",
      "    epsilon_step: 0.0005\n",
      "adaptive_epsilon_greedy:\n",
      "  dynamic_plot:\n",
      "    init_epsilon_min: 0.001\n",
      "    init_epsilon_max: 0.5\n",
      "    init_epsilon_step: 0.01\n",
      "    init_epsilon_default_value: 0.1\n",
      "    min_epsilon_min: 0.001\n",
      "    min_epsilon_max: 0.1\n",
      "    min_epsilon_step: 0.001\n",
      "    min_epsilon_default_value: 0.05\n",
      "  evaluation:\n",
      "    init_epsilon_min: 0.0001\n",
      "    init_epsilon_max: 0.1001\n",
      "    init_epsilon_step: 0.0005\n",
      "    min_epsilon: 0.05\n",
      "dynamic_adaptive_epsilon_greedy:\n",
      "  min_epsilon: 0.05\n",
      "  max_epsilon: 0.8\n",
      "  dynamic_plot:\n",
      "    init_epsilon_min: 0.001\n",
      "    init_epsilon_max: 0.5\n",
      "    init_epsilon_step: 0.01\n",
      "    init_epsilon_default_value: 0.1\n",
      "    percentiles_min: 50\n",
      "    percentiles_max: 100\n",
      "    percentiles_step: 1\n",
      "    percentiles_default_value: 80\n",
      "  evaluation:\n",
      "    init_epsilon_min: 0.0001\n",
      "    init_epsilon_max: 0.1001\n",
      "    init_epsilon_step: 0.0005\n",
      "    default_percentiles: 80\n",
      "    percentiles_min: 50\n",
      "    percentiles_max: 100\n",
      "    percentiles_step: 1\n",
      "    default_init_epsilon: 0.04\n",
      "boltzmann:\n",
      "  dynamic_plot:\n",
      "    temperature_min: 0.01\n",
      "    temperature_max: 1.01\n",
      "    temperature_step: 0.001\n",
      "    temperature_default_value: 0.5\n",
      "  evaluation:\n",
      "    temperature_min: 0.01\n",
      "    temperature_max: 0.25\n",
      "    temperature_step: 0.001\n",
      "thompson_sampling: null\n",
      "ucb:\n",
      "  dynamic_plot:\n",
      "    c_min: 0.001\n",
      "    c_max: 1\n",
      "    c_step: 0.001\n",
      "    c_default_value: 0.5\n",
      "  evaluation:\n",
      "    c_min: 0.001\n",
      "    c_max: 1.0\n",
      "    c_step: 0.001\n",
      "exp3:\n",
      "  dynamic_plot:\n",
      "    gamma_min: 0.001\n",
      "    gamma_max: 1.0\n",
      "    gamma_step: 0.001\n",
      "    gamma_default_value: 0.01\n",
      "  evaluation:\n",
      "    gamma_min: 0.001\n",
      "    gamma_max: 1.0\n",
      "    gamma_step: 0.001\n",
      "exp_ix:\n",
      "  dynamic_plot:\n",
      "    eta_min: 0.01\n",
      "    eta_max: 1.01\n",
      "    eta_step: 0.01\n",
      "    eta_default_value: 0.5\n",
      "  evaluation:\n",
      "    eta_min: 0.01\n",
      "    eta_max: 1.01\n",
      "    eta_step: 0.01\n",
      "exp4:\n",
      "  batch_size: 64\n",
      "  seq_length: 20\n",
      "  input_size: 10\n",
      "  output_size: 10\n",
      "  learning_rate: 0.001\n",
      "  num_workers: 16\n",
      "  num_epochs: 100\n",
      "  device: cuda\n",
      "  mix_precision: true\n",
      "  patience_epochs: 6\n",
      "  min_delta: 0.001\n",
      "  mode: min\n",
      "  factor: 0.1\n",
      "  patience_lr: 2\n",
      "  min_lr: 1.0e-06\n",
      "  threshold: 0.01\n",
      "  ARconfig:\n",
      "    order: 5\n",
      "  LSTMconfig:\n",
      "    hidden_size: 128\n",
      "    num_layers: 4\n",
      "    dropout_prob: 0.2\n",
      "    weight_decay: 0.0001\n",
      "  GNNconfig:\n",
      "    hidden_size: 128\n",
      "    num_layers: 4\n",
      "\n",
      "---------- Path Info ----------\n",
      "Global Path: E:\\Study in the UK\\Project\\MScProject\n",
      "Data Path: E:\\Study in the UK\\Project\\MScProject\\Data\n"
     ]
    }
   ],
   "source": [
    "# 配置管理\n",
    "config = DataInit.config_manager()\n",
    "\n",
    "# 路径管理\n",
    "global_path, data_path, load_latency_original_csv_path, rewards_npy_path, models_pkl_path = DataInit.path_manager(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e40089d4f14aa4",
   "metadata": {},
   "source": [
    "# Reward优化尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d7c6ad338e45f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T01:54:28.154425Z",
     "start_time": "2024-08-26T01:54:28.151410Z"
    }
   },
   "outputs": [],
   "source": [
    "# 设置渲染器为notebook\n",
    "# pio.renderers.default = \"notebook\"\n",
    "# pio.renderers.default = \"notebook_connected\"\n",
    "# pio.renderers.default = \"browser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634f831b5d7c2572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T01:54:29.036663Z",
     "start_time": "2024-08-26T01:54:28.165987Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\Study in the UK\\\\Project\\\\MScProject\\\\Data\\\\load_iid_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m iid_load \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_iid_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      2\u001b[0m ar1_load \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ar1_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      3\u001b[0m iid_latency \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_path\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatency_iid_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mD:\\Program\\Anaconda3\\envs\\Project\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\Program\\Anaconda3\\envs\\Project\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\Program\\Anaconda3\\envs\\Project\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\Program\\Anaconda3\\envs\\Project\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\Program\\Anaconda3\\envs\\Project\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\Study in the UK\\\\Project\\\\MScProject\\\\Data\\\\load_iid_data.csv'"
     ]
    }
   ],
   "source": [
    "iid_load = pd.read_csv(data_path/'load_iid_data.csv').values\n",
    "ar1_load = pd.read_csv(data_path/'load_ar1_data.csv').values\n",
    "iid_latency = pd.read_csv(data_path/'latency_iid_data.csv').values\n",
    "ar1_latency = pd.read_csv(data_path/'latency_ar1_data.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce84befbc543a47d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T01:54:29.040677600Z",
     "start_time": "2024-08-24T10:03:50.004021Z"
    }
   },
   "outputs": [],
   "source": [
    "class RewardDataProcessor:\n",
    "    def __init__(self, load_iid, latency_iid, load_ar1, latency_ar1: np.ndarray, reward_parameters_slider):\n",
    "        self.load_iid = load_iid\n",
    "        self.latency_iid = latency_iid\n",
    "        self.load_ar1 = load_ar1\n",
    "        self.latency_ar1 = latency_ar1\n",
    "\n",
    "        # 保存reward_parameters_slider的相关参数到self\n",
    "        self.alpha_load_0_value = reward_parameters_slider.alpha_load_0.value\n",
    "        self.alpha_load_0_min = reward_parameters_slider.alpha_load_0.min\n",
    "        self.alpha_load_0_max = reward_parameters_slider.alpha_load_0.max\n",
    "        self.alpha_load_0_step = reward_parameters_slider.alpha_load_0.step\n",
    "        self.alpha_load_0_description = reward_parameters_slider.alpha_load_0.description\n",
    "        \n",
    "        self.alpha_latency_0_value = reward_parameters_slider.alpha_latency_0.value\n",
    "        self.alpha_latency_0_min = reward_parameters_slider.alpha_latency_0.min\n",
    "        self.alpha_latency_0_max = reward_parameters_slider.alpha_latency_0.max\n",
    "        self.alpha_latency_0_step = reward_parameters_slider.alpha_latency_0.step\n",
    "        self.alpha_latency_0_description = reward_parameters_slider.alpha_latency_0.description\n",
    "        \n",
    "        self.alpha_latency_1_value = reward_parameters_slider.alpha_latency_1.value\n",
    "        self.alpha_latency_1_min = reward_parameters_slider.alpha_latency_1.min\n",
    "        self.alpha_latency_1_max = reward_parameters_slider.alpha_latency_1.max\n",
    "        self.alpha_latency_1_step = reward_parameters_slider.alpha_latency_1.step\n",
    "        self.alpha_latency_1_description = reward_parameters_slider.alpha_latency_1.description\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_reward(self, data: np.ndarray, method: str, alpha: float = 1) -> np.ndarray:\n",
    "        if method == 'load_0' or method == 'latency_0':\n",
    "            return alpha / (1 + data)\n",
    "        elif method == 'load_1':\n",
    "            inverted_data = 1 / (1 + data)\n",
    "            normalized_data = (inverted_data - inverted_data.min(axis=0)) / (inverted_data.max(axis=0) - inverted_data.min(axis=0))\n",
    "            return normalized_data\n",
    "        elif method == 'latency_1':\n",
    "            return np.exp(-alpha * data)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    \n",
    "    def calculate_subtitle(self, data: np.ndarray, title: str = \"\") -> str:\n",
    "        mean_values = np.mean(data, axis=1)\n",
    "        range_value = np.max(mean_values) - np.min(mean_values)\n",
    "        sorted_indices = np.argsort(-mean_values)\n",
    "        sorted_nodes = \", \".join(map(str, sorted_indices))\n",
    "        return f\"{title}<br>range: {range_value:.3f}<br>{sorted_nodes}\"\n",
    "\n",
    "    def plot_single_mean(self, fig, data: np.ndarray, row: int, col: int, dynamic_y: bool = False, title: str = ''):\n",
    "        mean_values = np.mean(data, axis=1)\n",
    "        \n",
    "        # 计算当前的最大值和最小值\n",
    "        y_max, y_min = np.max(mean_values), np.min(mean_values)\n",
    "        range_value = y_max - y_min\n",
    "\n",
    "        # 找到最大值和最小值的索引\n",
    "        max_index, min_index = np.argmax(mean_values), np.argmin(mean_values)\n",
    "    \n",
    "        # 添加折线图到子图\n",
    "        fig.add_trace(go.Scatter(x=np.arange(len(mean_values)), y=mean_values, \n",
    "                                 mode='lines+markers', name=title), row=row, col=col)\n",
    "\n",
    "        # 添加最大值和最小值的标记\n",
    "        fig.add_annotation(x=max_index, y=y_max, text=f'Max: {y_max:.3f} at x={max_index}',\n",
    "                           showarrow=True, arrowhead=2, font=dict(color=\"red\"), \n",
    "                           row=row, col=col)\n",
    "        fig.add_annotation(x=min_index, y=y_min, text=f'Min: {y_min:.3f} at x={min_index}',\n",
    "                           showarrow=True, arrowhead=2, font=dict(color=\"blue\"),\n",
    "                           row=row, col=col)\n",
    "\n",
    "        # 固定y轴范围，仅当最大值和最小值在0到1之间时，才将范围固定在[0, 1]，否则，使用实际的最小值和最大值范围\n",
    "        y_range = [0, 1] if dynamic_y and y_min >= 0 and y_max <= 1 else [y_min - 0.1 * range_value, y_max + 0.1 * range_value]\n",
    "\n",
    "    \n",
    "    def plot_mean_values(self, alpha_load_0: float, alpha_latency_0: float, alpha_latency_1: float, dynamic_y: bool = False, data_method: str = 'iid'):\n",
    "        data_map = {'iid': (self.load_iid, self.latency_iid), 'ar1': (self.load_ar1, self.latency_ar1)}\n",
    "        load_data, latency_data = data_map[data_method]\n",
    "\n",
    "        rewards = {\n",
    "            'Load Original data': load_data,\n",
    "            'Load Reward 0': self.calculate_reward(load_data, 'load_0', alpha_load_0),\n",
    "            'Load Reward 1': self.calculate_reward(load_data, 'load_1'),\n",
    "            'Latency Original data': latency_data,\n",
    "            'Latency Reward 0': self.calculate_reward(latency_data, 'latency_0', alpha_latency_0),\n",
    "            'Latency Reward 1': self.calculate_reward(latency_data, 'latency_1', alpha_latency_1)\n",
    "        }\n",
    "\n",
    "        # 计算子图标题\n",
    "        fig = make_subplots(rows=2, cols=3, subplot_titles=[self.calculate_subtitle(rewards[key], title=key) for key in rewards])\n",
    "\n",
    "        # 在不同的子图中绘制图表\n",
    "        for i, (title, data) in enumerate(rewards.items()):\n",
    "            self.plot_single_mean(fig, data, row=i // 3 + 1, col=i % 3 + 1, dynamic_y=dynamic_y, title=title)\n",
    "   \n",
    "        # 调整总标题位置，居中对齐，并增加顶部边距\n",
    "        fig.update_layout(\n",
    "            height=500, \n",
    "            width=1000, \n",
    "            title_text=\"Mean Values across Different Rewards\",\n",
    "            title_y=0.98,  # 标题的位置，1.0为图表的顶部边缘\n",
    "            title_x=0.5,  # 标题居中\n",
    "            title_xanchor='center',  # 确保标题是居中对齐的\n",
    "            margin=dict(t=100)  # 增加顶部边距\n",
    "        )\n",
    "    \n",
    "        fig.show()\n",
    "\n",
    "    \n",
    "    def calculate_range_over_alpha(self, alpha_load_0, alpha_latency_0, alpha_latency_1):\n",
    "        ranges = {'iid': {}, 'ar1': {}}\n",
    "        for method in ['iid', 'ar1']:\n",
    "            load_data, latency_data = (self.load_iid, self.latency_iid) if method == 'iid' else (self.load_ar1, self.latency_ar1)\n",
    "            ranges[method]['load_reward_0'] = [np.ptp(self.calculate_reward(load_data, 'load_0', alpha).mean(axis=1)) for alpha in alpha_load_0]\n",
    "            ranges[method]['latency_reward_0'] = [np.ptp(self.calculate_reward(latency_data, 'latency_0', alpha).mean(axis=1)) for alpha in alpha_latency_0]\n",
    "            ranges[method]['latency_reward_1'] = [np.ptp(self.calculate_reward(latency_data, 'latency_1', alpha).mean(axis=1)) for alpha in alpha_latency_1]\n",
    "        return ranges\n",
    "\n",
    "    def plot_range_vs_alpha(self, alpha_values_load_0, alpha_values_latency_0, alpha_values_latency_1):\n",
    "        ranges = self.calculate_range_over_alpha(alpha_values_load_0, alpha_values_latency_0, alpha_values_latency_1)\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(18, 6))\n",
    "\n",
    "        def add_plot(ax, alpha_values, ranges, title, color):\n",
    "            ax.plot(alpha_values, ranges, marker='o', linestyle='-', color=color)\n",
    "            ax.set_title(title)\n",
    "            ax.set_xlabel('Alpha')\n",
    "            ax.set_ylabel('Range (Max - Min)')\n",
    "            ax.grid(True)\n",
    "\n",
    "            # 找到最大值和最小值及其索引\n",
    "            max_value = np.max(ranges)\n",
    "            min_value = np.min(ranges)\n",
    "            max_index = np.argmax(ranges)\n",
    "            min_index = np.argmin(ranges)\n",
    "    \n",
    "            # 在图中标注最大值和最小值的位置\n",
    "            ax.annotate(f'Max range: {max_value:.3f} at alpha={alpha_values[max_index]:.3f}',\n",
    "                        xy=(alpha_values[max_index], max_value), \n",
    "                        xycoords='data',\n",
    "                        xytext=(alpha_values[max_index], max_value + 0.05 * max_value), \n",
    "                        textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"->\", lw=1.5, color='red'),\n",
    "                        color='red')\n",
    "    \n",
    "            ax.annotate(f'Min range: {min_value:.3f} at alpha={alpha_values[min_index]:.3f}',\n",
    "                        xy=(alpha_values[min_index], min_value), \n",
    "                        xycoords='data',\n",
    "                        xytext=(alpha_values[min_index], min_value - 0.05 * min_value), \n",
    "                        textcoords='data',\n",
    "                        arrowprops=dict(arrowstyle=\"->\", lw=1.5, color='blue'),\n",
    "                        color='blue')\n",
    "\n",
    "        add_plot(axs[0, 0], alpha_values_load_0, ranges['iid']['load_reward_0'], 'IID Load Reward 0 vs Alpha', 'b')\n",
    "        add_plot(axs[0, 1], alpha_values_latency_0, ranges['iid']['latency_reward_0'], 'IID Latency Reward 0 vs Alpha', 'g')\n",
    "        add_plot(axs[0, 2], alpha_values_latency_1, ranges['iid']['latency_reward_1'], 'IID Latency Reward 1 vs Alpha', 'r')\n",
    "        add_plot(axs[1, 0], alpha_values_load_0, ranges['ar1']['load_reward_0'], 'AR1 Load Reward 0 vs Alpha', 'b')\n",
    "        add_plot(axs[1, 1], alpha_values_latency_0, ranges['ar1']['latency_reward_0'], 'AR1 Latency Reward 0 vs Alpha', 'g')\n",
    "        add_plot(axs[1, 2], alpha_values_latency_1, ranges['ar1']['latency_reward_1'], 'AR1 Latency Reward 1 vs Alpha', 'r')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "            \n",
    "    def plot_distributions(self, axs, load_data, start, end, title='Load Data', row=0):\n",
    "        for i in range(start, end):\n",
    "            axs[row, 0].plot(load_data[i], label=f'Node {i}')\n",
    "        axs[row, 0].set_title(title)\n",
    "        axs[row, 0].set_xlabel('Time')\n",
    "        axs[row, 0].set_ylabel('Load')\n",
    "        axs[row, 0].legend()\n",
    "        axs[row, 0].grid(True)\n",
    "\n",
    "        mean_values = np.mean(load_data, axis=1)\n",
    "        axs[row, 1].plot(mean_values, marker='o', linestyle='-', color='b', label='Mean Load per Node')\n",
    "        axs[row, 1].set_title(f'{title} - Mean Values')\n",
    "        axs[row, 1].set_xlabel('Node')\n",
    "        axs[row, 1].set_ylabel('Mean Load')\n",
    "        axs[row, 1].legend()\n",
    "        axs[row, 1].grid(True)\n",
    "\n",
    "        y_max = mean_values.max()\n",
    "        y_min = mean_values.min()\n",
    "        range_value = y_max - y_min\n",
    "\n",
    "        axs[row, 1].text(len(mean_values) - 1, (y_max + y_min) / 2,\n",
    "                         f'Range: {range_value:.3f}',\n",
    "                         ha='right', va='center', fontsize=10, color='red')\n",
    "\n",
    "        axs[row, 1].hlines([y_min, y_max], xmin=0, xmax=len(mean_values) - 1, colors='red', linestyles='--', label='Range')\n",
    "        axs[row, 1].legend()\n",
    "\n",
    "        for i in range(start, end):\n",
    "            axs[row, 2].hist(load_data[i].flatten(), bins=30, alpha=0.2, label=f'Node {i}')\n",
    "        axs[row, 2].set_title(f'{title} - Histogram')\n",
    "        axs[row, 2].set_xlabel('Value')\n",
    "        axs[row, 2].set_ylabel('Frequency')\n",
    "        axs[row, 2].legend()\n",
    "        axs[row, 2].grid(True)\n",
    "\n",
    "    def plot_all_distributions(self, alpha_load=1.0, alpha_latency_0=1.0, alpha_latency_1=1.0, start=0, end=3, data_method='iid'):\n",
    "        data_map = {'iid': (self.load_iid, self.latency_iid), 'ar1': (self.load_ar1, self.latency_ar1)}\n",
    "        load_data, latency_data = data_map[data_method]\n",
    "\n",
    "        rewards = {\n",
    "            'Load Original data': load_data,\n",
    "            'Load Reward 0': self.calculate_reward(load_data, 'load_0', alpha_load),\n",
    "            'Load Reward 1': self.calculate_reward(load_data, 'load_1'),\n",
    "            'Latency Original data': latency_data,\n",
    "            'Latency Reward 0': self.calculate_reward(latency_data, 'latency_0', alpha_latency_0),\n",
    "            'Latency Reward 1': self.calculate_reward(latency_data, 'latency_1', alpha_latency_1)\n",
    "        }\n",
    "\n",
    "        fig, axs = plt.subplots(6, 3, figsize=(18, 14))\n",
    "\n",
    "        for i, (key, data) in enumerate(rewards.items()):\n",
    "            alpha_info = f\", alpha={alpha_load if 'Load' in key else alpha_latency_0 if 'Latency Reward 0' in key else alpha_latency_1}\"\n",
    "            title = f'{key}{alpha_info}'\n",
    "            self.plot_distributions(axs, data, start, end, title=title, row=i)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def create_interactive_plot(self):\n",
    "        # Custom slider and button styles\n",
    "        style = {'description_width': 'initial'}\n",
    "        slider_layout = Layout(width='400px')\n",
    "        button_layout = Layout(width='150px')\n",
    "\n",
    "        # Create sliders using the instance's self attributes\n",
    "        alpha_load_0 = FloatSlider(value=self.alpha_load_0_value, min=self.alpha_load_0_min, max=self.alpha_load_0_max, step=self.alpha_load_0_step, description=self.alpha_load_0_description, style=style, layout=slider_layout)\n",
    "        alpha_latency_0 = FloatSlider(value=self.alpha_latency_0_value, min=self.alpha_latency_0_min, max=self.alpha_latency_0_max, step=self.alpha_latency_0_step, description=self.alpha_latency_0_description, style=style, layout=slider_layout)\n",
    "        alpha_latency_1 = FloatSlider(value=self.alpha_latency_1_value, min=self.alpha_latency_1_min, max=self.alpha_latency_1_max, step=self.alpha_latency_1_step, description=self.alpha_latency_1_description, style=style, layout=slider_layout)\n",
    "\n",
    "        # Create toggle buttons\n",
    "        dynamic_y = ToggleButtons(options=[True, False], value=False, description='dynamic_y', style=style, layout=button_layout)\n",
    "        data_method = ToggleButtons(options=['iid', 'ar1'], value='iid', description='data_method', style=style, layout=button_layout)\n",
    "\n",
    "        # Arrange sliders in a vertical box\n",
    "        sliders = VBox([alpha_load_0, alpha_latency_0, alpha_latency_1])\n",
    "\n",
    "        # Arrange buttons in a horizontal box\n",
    "        buttons = HBox([dynamic_y, data_method])\n",
    "\n",
    "        # Combine sliders and buttons in a single horizontal box\n",
    "        ui = HBox([sliders, buttons])\n",
    "\n",
    "        # Define the interaction function\n",
    "        def plot_mean_values(alpha_load_0, alpha_latency_0, alpha_latency_1, dynamic_y, data_method):\n",
    "            self.plot_mean_values(alpha_load_0, alpha_latency_0, alpha_latency_1, dynamic_y, data_method)\n",
    "\n",
    "        # Create the interactive widget, but don't automatically display\n",
    "        interactive_plot = interactive(plot_mean_values,\n",
    "                                       alpha_load_0=alpha_load_0,\n",
    "                                       alpha_latency_0=alpha_latency_0,\n",
    "                                       alpha_latency_1=alpha_latency_1,\n",
    "                                       dynamic_y=dynamic_y,\n",
    "                                       data_method=data_method)\n",
    "\n",
    "        # Extract the output part, to avoid duplicating controls\n",
    "        output = interactive_plot.children[-1]\n",
    "        interactive_plot.children = interactive_plot.children[:-1]\n",
    "\n",
    "        # Display the controls and the output\n",
    "        display(ui, output)\n",
    "\n",
    "    def plot_range_vs_alpha_interactive(self):\n",
    "        # 定义 alpha 的取值范围\n",
    "        alpha_values_load_0 = np.arange(self.alpha_load_0_min, self.alpha_load_0_max, self.alpha_load_0_step)\n",
    "        alpha_values_latency_0 = np.arange(self.alpha_latency_0_min, self.alpha_latency_0_max, self.alpha_latency_0_step)\n",
    "        alpha_values_latency_1 = np.arange(self.alpha_latency_1_min, self.alpha_latency_1_max, self.alpha_latency_1_step)\n",
    "\n",
    "        # 调用 plot_range_vs_alpha 方法\n",
    "        self.plot_range_vs_alpha(alpha_values_load_0, alpha_values_latency_0, alpha_values_latency_1)\n",
    "\n",
    "    def plot_all_distributions_interactive(self):\n",
    "        # 自定义宽度的滑块\n",
    "        style = {'description_width': 'initial'}\n",
    "        slider_layout = Layout(width='400px')\n",
    "\n",
    "        # 使用 self 的属性创建滑块\n",
    "        alpha_load = FloatSlider(value=self.alpha_load_0_value, min=self.alpha_load_0_min, max=self.alpha_load_0_max, step=self.alpha_load_0_step, description=self.alpha_load_0_description, style=style, layout=slider_layout)\n",
    "        alpha_latency_0 = FloatSlider(value=self.alpha_latency_0_value, min=self.alpha_latency_0_min, max=self.alpha_latency_0_max, step=self.alpha_latency_0_step, description=self.alpha_latency_0_description, style=style, layout=slider_layout)\n",
    "        alpha_latency_1 = FloatSlider(value=self.alpha_latency_1_value, min=self.alpha_latency_1_min, max=self.alpha_latency_1_max, step=self.alpha_latency_1_step, description=self.alpha_latency_1_description, style=style, layout=slider_layout)\n",
    "\n",
    "        # 创建其他控件\n",
    "        start = IntSlider(value=0, min=0, max=10, step=1, description='start', style=style, layout=slider_layout)\n",
    "        end = IntSlider(value=3, min=1, max=10, step=1, description='end', style=style, layout=slider_layout)\n",
    "        data_method = ToggleButtons(options=['iid', 'ar1'], value='iid', description='data_method', style=style, layout=slider_layout)\n",
    "\n",
    "        # 创建交互式控件\n",
    "        interact(self.plot_all_distributions, \n",
    "                 alpha_load=alpha_load, \n",
    "                 alpha_latency_0=alpha_latency_0, \n",
    "                 alpha_latency_1=alpha_latency_1,\n",
    "                 start=start, \n",
    "                 end=end, \n",
    "                 data_method=data_method)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce75a800792b787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T01:54:29.041677400Z",
     "start_time": "2024-08-24T10:03:50.309452Z"
    }
   },
   "outputs": [],
   "source": [
    "data_processor = RewardDataProcessor(iid_load, iid_latency, ar1_load, ar1_latency, config.data_generation.reward_parameters_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88e0685f22590a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T01:54:29.041677400Z",
     "start_time": "2024-08-24T10:03:50.916218Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_processor.create_interactive_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c3fc69acb9bf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T01:54:29.041677400Z",
     "start_time": "2024-08-24T10:00:34.859951Z"
    }
   },
   "outputs": [],
   "source": [
    "data_processor.plot_range_vs_alpha_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618fba6d8fdc905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T01:54:29.063784800Z",
     "start_time": "2024-08-24T10:00:38.941922Z"
    }
   },
   "outputs": [],
   "source": [
    "data_processor.plot_all_distributions_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bdbc2674857d87",
   "metadata": {},
   "source": [
    "# reward_parameters 结论:\n",
    "iid 数据：\n",
    "    load\n",
    "        若使用倒数方案，可以将alpha设置为40，此时方差最大\n",
    "        若使用reward_1方案，即先取倒数，然后用max-min方法，可以尝试\n",
    "        这两种方案的直方图差异较大。不好说MAB效果。可以都试试。\n",
    "    latency\n",
    "        使用np.exp(-alpha * data)方案，根据观察的输出图片结果，将alpha设置为0.041时，其均值分布方差最大。适合执行MAB算法。\n",
    "ar1 数据：\n",
    "    load\n",
    "        若使用倒数方案，alpha设置为40也比较合适\n",
    "        也可使用reward_1方案\n",
    "    latency\n",
    "        alpha也设置为0.041的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437837272c42f9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
